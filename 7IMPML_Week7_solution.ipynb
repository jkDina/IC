{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7, K-Nearest Neighbors\n",
    "\n",
    "**_Author: Jessica Cervi_**\n",
    "\n",
    "**Expected time = 2 hours**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment overview\n",
    "\n",
    "\n",
    "In this assignment, you will work with k-nearest neighbors to classify wine quality using pandas, NumPy, and sklearn Python packages. You will use pandas to import the data set and convert the data into NumPy arrays to prepare it for classification using sklearn. You will then split the data set into a training data set and a test data set. From there, you will use sklearn to normalize the data sets, train the classifier, and use cross-validation to select the best k. Finally, you will evaluate the selected classifier using the test data set. \n",
    "\n",
    "This assignment is designed to help you apply the machine learning algorithms you have learnt using packages in Python. Python concepts, instructions, and starter code are embedded within this Jupyter Notebook to help guide you as you progress through the assignment. Remember to run the code of each code cell prior to submitting the assignment. Upon completing the assignment, we encourage you to compare your work against the solution file to perform a self-assessment.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Outline k-nearest neighbours for classification\n",
    "- Define the concept of proximity for k-nearest neighbours methods\n",
    "- Convert binary and categorical predictors into numbers\n",
    "- Explain the relationship between selecting k and the bias-variance trade-off\n",
    "- Outline k-nearest neighbours for regression\n",
    "- Discuss real-life applications of k-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index:\n",
    "\n",
    "\n",
    "#### Week 7:  K-Nearest Neighbors\n",
    "\n",
    "- [Part 1 - Importing the data set and exploratory data analysis (EDA)](#part1)\n",
    "- [Part 2 - Creating a new binary column for good_wines](#part2)\n",
    "- [Part 3 - Moving the Data to NumPy arrays and splitting the data set](#part3)\n",
    "- [Part 4 - Data normalisation](#part4)\n",
    "- [Part 5-  Loading and training the classifier](#part5)\n",
    "- [Part 6 - Evaluate and select the best classifier](#part6)\n",
    "- [Part 7 - Predict the generalisation error using the test data set](#part7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Week 7:  K-nearest neighbors\n",
    "\n",
    "\n",
    "In Week 7, you learnt about **k-nearest neighbors** (KNN) for classification. \n",
    "\n",
    "The KNN algorithm is one of the simplest classification algorithms. KNN is used to predict the classification of a new sample point, based on data sets that are made up of data which are separated into several classes or categories.\n",
    "\n",
    "The pseudo-algorithm for KNN can be summarised as follows:\n",
    "1. Load the training and test data \n",
    "2. Choose the value of K \n",
    "3. For each point in test data:\n",
    "   - Find the Euclidean distance to all training data points\n",
    "   - Store the Euclidean distances in a list and sort it \n",
    "   - Choose the first k points \n",
    "   - Assign a class to the test point based on the majority of classes present in the chosen points\n",
    "4. Review ouput "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Predicting wine quality with k-nearest neighbors\n",
    "\n",
    "\n",
    "For this exercise, we will use the data set  'sparklingwine.csv' to predict wine quality and we will build a KNN classifier in Python for the data set by following the steps given below\n",
    "\n",
    "1. Load the data file\n",
    "2. Construct a new binary column 'good wine' that indicates whether the wine is good\n",
    "(which we define as having a quality of 6 or higher) or not\n",
    "3. Move the data to NumPy arrays and split the data set into a training data set (first 400 samples), a validation data set (next 200 samples) and a test data set (last 200 samples)\n",
    "4. Normalise the data according to the Z-score transform\n",
    "5. Load and train the k-nearest neighbors classifiers for k = 1,2, ...,100\n",
    "6. Evaluate each classifier using the validation data set and select the best classifier\n",
    "7. Predict the generalisation error using the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1 - Importing the dataset and exploratory data analysis (EDA)\n",
    "\n",
    "We begin by using `pandas` to import the data set. To do so, we import `pandas` first and we read the file using the `.read_csv()` function by passing the name of the data set we want to read as a string.\n",
    "\n",
    "Notice that, because the columns in the data set are separated using a `;`, we have specified the type of delimiter in the `.read_csv()` function (the default value is `,`).\n",
    "\n",
    "Complete the code cell below adding the name of the data set inside `.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sparklingwine.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any algorithm on the dataframe, it is always good practice to perform exploratory data analysis.\n",
    "\n",
    "We begin by visualising the first *ten* rows of the dataframe `df` using the function `.head()`. By default, `.head()` displays the first five rows of a dataframe. \n",
    "\n",
    "Complete the code cell below by passing the desired number of rows to the function `.head()` as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.065</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "5            7.4              0.66         0.00             1.8      0.075   \n",
       "6            7.9              0.60         0.06             1.6      0.069   \n",
       "7            7.3              0.65         0.00             1.2      0.065   \n",
       "8            7.8              0.58         0.02             2.0      0.073   \n",
       "9            7.5              0.50         0.36             6.1      0.071   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "5                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "6                 15.0                  59.0   0.9964  3.30       0.46   \n",
       "7                 15.0                  21.0   0.9946  3.39       0.47   \n",
       "8                  9.0                  18.0   0.9968  3.36       0.57   \n",
       "9                 17.0                 102.0   0.9978  3.35       0.80   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        5  \n",
       "4      9.4        5  \n",
       "5      9.4        5  \n",
       "6      9.4        5  \n",
       "7     10.0        5  \n",
       "8      9.5        5  \n",
       "9     10.5        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve some more information about our dataframe by using the properties `.shape` and `.columns` and the function `.describe()`.\n",
    "\n",
    "Here's a brief description of what each of the above functions does:\n",
    "\n",
    "- `.shape`: Returns a tuple representing the dimensionality of the dataframe.\n",
    "- `.columns`: Returns the column labels of the dataframe.\n",
    "- `.describe()`: Returns summary statistics of the columns in the dataframe provided, such as mean, count, standad deviation and so on.\n",
    "\n",
    "\n",
    "Run the cells below to get information about the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>8.860750</td>\n",
       "      <td>0.539938</td>\n",
       "      <td>0.303875</td>\n",
       "      <td>2.617938</td>\n",
       "      <td>0.093080</td>\n",
       "      <td>14.946250</td>\n",
       "      <td>50.710000</td>\n",
       "      <td>0.997646</td>\n",
       "      <td>3.285338</td>\n",
       "      <td>0.674375</td>\n",
       "      <td>10.098375</td>\n",
       "      <td>5.086250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.890583</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>0.206469</td>\n",
       "      <td>1.262319</td>\n",
       "      <td>0.054436</td>\n",
       "      <td>9.725725</td>\n",
       "      <td>34.295205</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.158945</td>\n",
       "      <td>0.195282</td>\n",
       "      <td>0.979967</td>\n",
       "      <td>0.494081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.991200</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.996600</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>3.290000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>1.003200</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count     800.000000        800.000000   800.000000      800.000000   \n",
       "mean        8.860750          0.539938     0.303875        2.617938   \n",
       "std         1.890583          0.180819     0.206469        1.262319   \n",
       "min         4.600000          0.180000     0.000000        1.200000   \n",
       "25%         7.500000          0.407500     0.120000        2.000000   \n",
       "50%         8.400000          0.530000     0.280000        2.300000   \n",
       "75%        10.000000          0.645000     0.490000        2.800000   \n",
       "max        15.900000          1.330000     1.000000       15.500000   \n",
       "\n",
       "        chlorides  free sulfur dioxide  total sulfur dioxide     density  \\\n",
       "count  800.000000           800.000000            800.000000  800.000000   \n",
       "mean     0.093080            14.946250             50.710000    0.997646   \n",
       "std      0.054436             9.725725             34.295205    0.001683   \n",
       "min      0.034000             1.000000              8.000000    0.991200   \n",
       "25%      0.073000             7.000000             24.000000    0.996600   \n",
       "50%      0.082000            12.000000             41.500000    0.997500   \n",
       "75%      0.094000            20.000000             66.000000    0.998650   \n",
       "max      0.611000            68.000000            165.000000    1.003200   \n",
       "\n",
       "               pH   sulphates     alcohol     quality  \n",
       "count  800.000000  800.000000  800.000000  800.000000  \n",
       "mean     3.285338    0.674375   10.098375    5.086250  \n",
       "std      0.158945    0.195282    0.979967    0.494081  \n",
       "min      2.740000    0.330000    8.400000    4.000000  \n",
       "25%      3.180000    0.560000    9.400000    5.000000  \n",
       "50%      3.290000    0.620000    9.800000    5.000000  \n",
       "75%      3.380000    0.740000   10.500000    5.000000  \n",
       "max      3.900000    2.000000   14.900000    7.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2 - Creating a new binary column for good wines\n",
    "\n",
    "For the second step of this exercise, we will construct a new binary column `good_wine` that indicates whether a wine is good or not.\n",
    "\n",
    "Because the values in the new column `good_wine` will be based on the values in the column `quality`, we will use the function `.apply()`, which allows us to pass a user-defined function and apply it to every single value of the pandas series (`quality` in this case). \n",
    "\n",
    "`.apply()` takes, at least, the Python or the `NumPy` function to apply. Additional arguments can be passed as well, a detailed description can be found [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html).\n",
    "\n",
    "In the code cell below, complete the definition of the function `goodwine`. Your function should take, as input, the column `quality`. Based on whether the values in `quality` are greater than or equal to six, your function should return  1 or 0 otherwise. Remember, your function should look something like the below, and you should fill in the function-name, function-input, and integer values. \n",
    "\n",
    "`def function-name (function-input):\n",
    "    if function-input >= integer :\n",
    "        return integer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def goodwine(quality): \n",
    "    if quality >= 6:\n",
    "        return 1 \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the `.apply()` function to create the new column.\n",
    "\n",
    "Complete the code in the cell below by creating a new column in the dataframe `df` called `good_wine` and by passing the function `goodwine` as an argument to the function `.apply()`.\n",
    "\n",
    "*Hint: New columns need to be passed to the dataframe as strings. As you may remember, a string is enclosed in quotation marks like \"string.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"good_wine\"] = df.quality.apply(goodwine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualise the dataframe again. Observe that now the dataframe has a new column `good_wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>good_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.132</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99786</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.18</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.126</td>\n",
       "      <td>24.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.99746</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.038</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99526</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99870</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0              7.4              0.70         0.00             1.9      0.076   \n",
       "1              7.8              0.88         0.00             2.6      0.098   \n",
       "2              7.8              0.76         0.04             2.3      0.092   \n",
       "3             11.2              0.28         0.56             1.9      0.075   \n",
       "4              7.4              0.70         0.00             1.9      0.076   \n",
       "..             ...               ...          ...             ...        ...   \n",
       "795           10.8              0.89         0.30             2.6      0.132   \n",
       "796            8.7              0.46         0.31             2.5      0.126   \n",
       "797            9.3              0.37         0.44             1.6      0.038   \n",
       "798            9.4              0.50         0.34             3.6      0.082   \n",
       "799            9.4              0.50         0.34             3.6      0.082   \n",
       "\n",
       "     free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                   25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                   15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                   17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                   11.0                  34.0  0.99780  3.51       0.56   \n",
       "..                   ...                   ...      ...   ...        ...   \n",
       "795                  7.0                  60.0  0.99786  2.99       1.18   \n",
       "796                 24.0                  64.0  0.99746  3.10       0.74   \n",
       "797                 21.0                  42.0  0.99526  3.24       0.81   \n",
       "798                  5.0                  14.0  0.99870  3.29       0.52   \n",
       "799                  5.0                  14.0  0.99870  3.29       0.52   \n",
       "\n",
       "     alcohol  quality  good_wine  \n",
       "0        9.4        5          0  \n",
       "1        9.8        5          0  \n",
       "2        9.8        5          0  \n",
       "3        9.8        5          0  \n",
       "4        9.4        5          0  \n",
       "..       ...      ...        ...  \n",
       "795     10.2        5          0  \n",
       "796      9.6        5          0  \n",
       "797     10.8        6          1  \n",
       "798     10.7        5          0  \n",
       "799     10.7        5          0  \n",
       "\n",
       "[800 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have created a new column 'good wine' by passing a lambda function to `.apply()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"good wine\"] = df.quality.apply (lambda x : 1 if x>=6 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part3'></a>\n",
    "### Part 3 - Moving the data to NumPy arrays and splitting the data set\n",
    "\n",
    "The KNN algorithm is implemented in the SciKit-Learn package, which takes, as inputs, `NumPy` arrays.\n",
    "\n",
    "Now, we want to predict wine quality to complete column 13: `good_wine`. To do this, we will use all features (or columns in our dataframe) except `quality` (column 12) and `good_wine` (column 13). Hence, we will take the first 11 columns in our dataframe as features to predict the classification labels in the 13th column, `good_wine`.\n",
    "\n",
    "- To begin, we import the `NumPy` package. Alias the package as `np`.\n",
    "- We define `X` and `y` as `NumPy` arrays. So we will start with `X = np.array`.\n",
    "- `X` should be a two-dimensional `NumPy` array of predictors that contains the values of the first eleven columns in `df`.\n",
    "- `y` should be a one-dimensional `NumPy` array with the response variable entries of the column `good_wine`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array (df[df.columns[:11]]) \n",
    "y = np.array (df.good_wine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a sanity check, it is good practice to check the dimensions of `X` and `y`. \n",
    "\n",
    "Run the code cells below to obtain the shapes of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, according to the instructions, we split `X` into a training data set (first 400 samples), a validation data set (next 200 samples) and a test data set (last 200 samples). Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unproc = X[:400] \n",
    "X_val_unproc = X[400:600]\n",
    "X_test_unproc = X[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code cell below to split `y` in the sets `y_train`, `y_set`, and `y_test` in the way we split `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:400]\n",
    "y_val=y[400:600] \n",
    "y_test = y[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "\n",
    "<a id='part4'></a>\n",
    "### Part 4 - Data normalisation\n",
    "\n",
    "In this part, we are going to load and train the k-nearest neighbours classifiers for k = 1,2, ...,100.\n",
    "\n",
    "To do so, we are going to normalise the data, as the nearest neighbours classifier is sensitive to scaling. Standardisation of a data set is a common requirement for many machine learning estimators: the main idea is to normalise (mean = 0 and standard deviation = 1) your feature `X` before applying the machine learning techniques.\n",
    "\n",
    "Although here the training and the test sets are available in advance, we are going to take a general approach: we normalise according to the training data and apply the same transformation to the test set in a consistent manner.\n",
    "\n",
    "\n",
    "In the code cell below, import `.StandardScaler()` from the library `sklearn.preprocessing`. Next, use the `.StandardScaler()` function `.fit()` to compute the mean and standard deviation to be used for later scaling on the unprocessed training set `X_train_unproc`. Assign this to the variable `scaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the scaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "#Compute the mean and the std on the training set\n",
    "scaler = StandardScaler().fit(X_train_unproc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we scale the data by using the `.transform()` function on each unproccesed feature set.\n",
    "\n",
    "Run the cell below to obain the normalised `X` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform (X_train_unproc)\n",
    "X_val = scaler.transform (X_val_unproc)\n",
    "X_test = scaler.transform (X_test_unproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5-  Loading and training the classifier\n",
    "\n",
    "To load and train the classifier, we first need to import the nearest neighbours package.\n",
    "Complete the cell below by importing `KNeighborsClassifier` from the `sklearn.neighbors` package.\n",
    "\n",
    "Next, use ``KNeighborsClassifier`` to initialise the classifier `clf`, setting k = 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to train the classifier `clf` using `X_train` an `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train using the training sets\n",
    "clf.fit (X_train , y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our initial choice of k = 3, we evaluate the performance of the classifier on the training data, and\n",
    "we now estimate the performance on new data using the validation set, also known as the test set.\n",
    "\n",
    "This can be achieved by using the `SciKit-learn` function `.score()`.\n",
    "\n",
    "Compute the score on both the training and validation `X` and `y` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score on the training set\n",
    "clf.score(X_train, y_train)\n",
    "\n",
    "#score on the validation set\n",
    "clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6 - Evaluate and select the best classifier\n",
    "\n",
    "\n",
    "To evaluate and select the best classifier, we are going to use cross-validation to choose the value of `k` that has the most promising performance on future data.\n",
    "\n",
    "We do so by evaluating each classifier and computing the scores using the training and the validation sets.\n",
    "\n",
    "Define the classifier range `ks` as a sequence of integers from 1 to 100 with step 1, and define two empty lists `inSampleScores` and `valScores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the range for classifiers\n",
    "ks=range (1 ,100 ,1) \n",
    "\n",
    "inSampleScores =[] \n",
    "valScores =[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to evaluate each classifier and compute the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ks:\n",
    "    clf = KNeighborsClassifier(k).fit(X_train,y_train)\n",
    "    inSampleScores.append(clf.score(X_train, y_train)) \n",
    "    valScores.append(clf.score(X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we select the best classifier by plotting the scores for the training (in)  and the validation (out ) sets.\n",
    "\n",
    "To do so, import `plt` from the `matplotlib.pyplot` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#This command is necessary to display plots in Jupyter Notebooks\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to visualise a plot with the scores for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11a629590>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot\n",
    "p1 = plt.plot(ks, inSampleScores)\n",
    "p2 = plt.plot(ks , valScores )\n",
    "plt.legend(['in', 'out'], loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In analysing this plot, we see that for small values of k, the nearest neighbours classifier suffers from overfitting, whereas for large values of k, the classifer suffers from underfitting. Our plot indicates that a k around 15 is a reasonable choice. We will use this value when evaluating the selected classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 - Predict the generalisation error using the test data set.\n",
    "\n",
    "In the last part of this exercise, we will evaluate the classifier with k = 15 on the test set.\n",
    "\n",
    "Run the cell below, to compute the classifier for k=15 and to compute the predicted value of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(15).fit(X_train , y_train) \n",
    "\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, in the cell below compute the new score obtained by uning `X_test` and `y_test`. Assign the result to the variable `score_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
